# import nltk

# sentence = "我 是 李晓庆"
# tokens = nltk.word_tokenize(sentence)
# tagged = nltk.pos_tag(tokens)
#
# entities = nltk.chunk.ne_chunk(tagged)
# print(entities)
import fool
article = ''
words, ner = fool.analysis(article)